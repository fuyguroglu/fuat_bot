# Fuat_bot Configuration
# Copy this to .env and fill in your values

# ============================================================================
# LLM Provider Configuration
# ============================================================================

# Choose your LLM provider (anthropic, gemini, openai, or ollama)
LLM_PROVIDER=anthropic

# Anthropic API Key (get from https://console.anthropic.com/)
ANTHROPIC_API_KEY=sk-ant-...

# Google Gemini API Key (get from https://makersuite.google.com/app/apikey)
# GEMINI_API_KEY=...

# OpenAI API Key (get from https://platform.openai.com/)
# OPENAI_API_KEY=sk-...

# Model to use
# For Anthropic: claude-sonnet-4-20250514, claude-opus-4-20250514, etc.
# For Gemini: models/gemini-2.5-flash, models/gemini-2.5-pro, models/gemini-2.0-flash, etc.
# For OpenAI: gpt-4, gpt-3.5-turbo, etc. (not yet implemented)
# For Ollama: llama3.3:70b, mistral:latest, phi3:latest, qwen2.5:32b, deepseek-r1:70b, etc.
MODEL_NAME=claude-sonnet-4-20250514

# ============================================================================
# Ollama Configuration (for local LLMs)
# ============================================================================

# Ollama base URL (default: http://localhost:11434/v1)
# Change if Ollama is running on a different host/port
# OLLAMA_BASE_URL=http://localhost:11434/v1

# Ollama model to use (must be pulled first with: ollama pull <model>)
# Popular models:
#   - llama3.3:70b (Meta's latest, very capable, requires ~40GB RAM)
#   - mistral:latest (Fast and efficient, ~4GB RAM)
#   - phi3:latest (Microsoft's small but powerful, ~2GB RAM)
#   - qwen2.5:32b (Alibaba's model, good at coding, ~18GB RAM)
#   - deepseek-r1:70b (DeepSeek's reasoning model, ~40GB RAM)
# OLLAMA_MODEL=llama3.3:70b

# Workspace directory (where the agent operates)
WORKSPACE_DIR=./workspace

# Session storage directory
SESSIONS_DIR=./sessions

# Memory Configuration
# Enable/disable the memory system
MEMORY_ENABLED=true

# Auto-inject memories into system prompt
MEMORY_INJECTION_ENABLED=true

# Maximum number of working memories to inject into system prompt
MEMORY_WORKING_LIMIT=10

# Maximum number of long-term facts to inject
MEMORY_FACTS_LIMIT=20

# Maximum number of semantic search results to use
MEMORY_SEMANTIC_LIMIT=5

# Embedding Configuration (for Phase 4 - semantic memory)
# Options: sentence-transformers (local, free) or openai (API, requires OPENAI_API_KEY)
EMBEDDING_PROVIDER=sentence-transformers

# Sentence-transformers model to use (if using sentence-transformers)
# Popular options: all-MiniLM-L6-v2 (fast, small), all-mpnet-base-v2 (slower, better quality)
EMBEDDING_MODEL=all-MiniLM-L6-v2

# ============================================================================
# RAG System Configuration (PDF Document Search)
# ============================================================================

# Enable/disable RAG system
RAG_ENABLED=true

# Chunking parameters
# Target chunk size in tokens (default: 500)
RAG_CHUNK_SIZE=500

# Overlap between chunks in tokens (default: 50)
RAG_CHUNK_OVERLAP=50

# Minimum chunk size to keep (default: 100)
RAG_MIN_CHUNK_SIZE=100

# Retrieval parameters
# Default number of results to return (default: 5)
RAG_RETRIEVAL_LIMIT=5

# Maximum allowed retrieval limit (default: 20)
RAG_MAX_RETRIEVAL_LIMIT=20

# Re-ranking configuration
# Enable cross-encoder re-ranking for better relevance (default: true)
RAG_RERANK_ENABLED=true

# Retrieve N times more results before re-ranking (default: 3)
# e.g., if limit=5 and multiplier=3, retrieves 15 then re-ranks to top 5
RAG_RERANK_MULTIPLIER=3

# Cross-encoder model for re-ranking (default: cross-encoder/ms-marco-MiniLM-L-6-v2)
# RAG_RERANK_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2

# Default category for documents (default: documents)
# RAG_DEFAULT_CATEGORY=documents

# Available categories (comma-separated list)
# RAG_CATEGORIES=regulations,course_materials,policies,syllabi,documents

# ============================================================================
# Google Calendar Configuration
# ============================================================================
# Setup steps:
#   1. Go to console.cloud.google.com → APIs & Services → Credentials
#   2. Create an OAuth 2.0 Client ID (Desktop app type)
#   3. Download the JSON and save it as credentials.json in the project root
#   4. Enable Google Calendar API in the API Library
#   5. Run: python -m fuat_bot calendar-setup  (one-time OAuth flow)

# Path to OAuth2 credentials JSON (downloaded from Google Cloud Console)
# GOOGLE_CALENDAR_CREDENTIALS_FILE=./credentials.json

# Path to store the OAuth2 token after setup (auto-created by calendar-setup)
# GOOGLE_CALENDAR_TOKEN_FILE=./token.json

# Which calendar to use (default: primary = your main calendar)
# GOOGLE_CALENDAR_ID=primary

# ============================================================================
# Email Configuration (SMTP + IMAP) — multi-account
# ============================================================================
# Setup for Gmail (repeat per account):
#   1. Enable 2-Step Verification on the Google account.
#   2. Go to Google Account → Security → App Passwords.
#   3. Generate an App Password and use it as "password" below.
#
# EMAIL_ACCOUNTS is a JSON object where each key is a short account name
# you choose (e.g. "personal", "work"). Only address and password are
# required — smtp/imap host+port default to Gmail values if omitted.
#
# EMAIL_ENABLED=false
# EMAIL_DEFAULT_ACCOUNT=personal
# EMAIL_ACCOUNTS={"personal": {"address": "you@gmail.com", "password": "app-pass-here"},
#                 "work":     {"address": "you@company.com", "password": "app-pass-here",
#                              "smtp_host": "smtp.office365.com", "smtp_port": 587,
#                              "imap_host": "outlook.office365.com", "imap_port": 993}}

# ============================================================================
# Telegram Bot Configuration (Phase 4)
# ============================================================================
# Setup steps:
#   1. Open Telegram and start a chat with @BotFather
#   2. Send /newbot — follow the prompts to name your bot
#   3. Copy the token it gives you into TELEGRAM_BOT_TOKEN below
#   4. Find your own Telegram user ID (e.g. message @userinfobot)
#   5. Add your ID to TELEGRAM_ALLOWED_USERS
#   6. Run: python -m fuat_bot telegram-start

# Enable the Telegram bot feature
# TELEGRAM_ENABLED=true

# Bot token from @BotFather
# TELEGRAM_BOT_TOKEN=123456789:ABC-your-token-here

# List of Telegram user IDs allowed to use the bot (JSON array of integers)
# Get your ID by messaging @userinfobot on Telegram
# TELEGRAM_ALLOWED_USERS=[123456789]

# Set to true to let anyone message the bot (no allowlist). Use with caution!
# TELEGRAM_OPEN_ACCESS=false

# Log level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO
